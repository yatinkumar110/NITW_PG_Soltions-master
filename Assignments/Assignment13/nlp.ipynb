{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_excel(\"ReviewsFileName.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the rock is destined to be the 21st century's ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the gorgeously elaborate continuation of \" the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>effective but too-tepid biopic\\n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you sometimes like to go to the movies to h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>emerges as something rare , an issue movie tha...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              Review  Sentiment\n0  the rock is destined to be the 21st century's ...          0\n1  the gorgeously elaborate continuation of \" the...          0\n2                   effective but too-tepid biopic\\n          0\n3  if you sometimes like to go to the movies to h...          0\n4  emerges as something rare , an issue movie tha...          0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10662"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the rock is destined to be the 21st century's ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the gorgeously elaborate continuation of \" the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>effective but too-tepid biopic\\n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you sometimes like to go to the movies to h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>emerges as something rare , an issue movie tha...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              Review  Sentiment\n0  the rock is destined to be the 21st century's ...          0\n1  the gorgeously elaborate continuation of \" the...          0\n2                   effective but too-tepid biopic\\n          0\n3  if you sometimes like to go to the movies to h...          0\n4  emerges as something rare , an issue movie tha...          0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def pre_process_data(data, remove_stop_words=True):\n",
    "\n",
    "    list_Sentiment = []\n",
    "    list_Review = []\n",
    "    len_data = len(df)\n",
    "    i=0\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        i+=1\n",
    "        if i % 500 == 0:\n",
    "            print(\"%s | %s rows\" % (i, len_data))\n",
    "\n",
    "        ##### Remove and clean comments\n",
    "        posts = row[1].Review\n",
    "        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', posts)\n",
    "        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "        temp = re.sub(' +', ' ', temp).lower()\n",
    "        if remove_stop_words:\n",
    "            temp = \" \".join([stemmer.stem(w) for w in temp.split(' ') if w not in cachedStopWords])\n",
    "        else:\n",
    "            temp = \" \".join([stemmer.stem(w) for w in temp.split(' ')])\n",
    "        list_Sentiment.append(row[1].Sentiment)\n",
    "        list_Review.append(temp)\n",
    "\n",
    "    #del data\n",
    "    list_Review = np.array(list_Review)\n",
    "    list_Sentiment = np.array(list_Sentiment)\n",
    "    return list_Review, list_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "500 | 10662 rows\n1000 | 10662 rows\n1500 | 10662 rows\n2000 | 10662 rows\n2500 | 10662 rows\n3000 | 10662 rows\n3500 | 10662 rows\n4000 | 10662 rows\n4500 | 10662 rows\n5000 | 10662 rows\n5500 | 10662 rows\n6000 | 10662 rows\n6500 | 10662 rows\n7000 | 10662 rows\n7500 | 10662 rows\n8000 | 10662 rows\n8500 | 10662 rows\n9000 | 10662 rows\n9500 | 10662 rows\n10000 | 10662 rows\n10500 | 10662 rows\n"
    }
   ],
   "source": [
    "list_Review, list_Sentiment = pre_process_data(df, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cntizer = CountVectorizer()\n",
    "X_cnt = cntizer.fit_transform(list_Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dic = {}\n",
    "for key in cntizer.vocabulary_:\n",
    "    reverse_dic[cntizer.vocabulary_[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['film',\n 'movi',\n 'like',\n 'one',\n 'make',\n 'stori',\n 'time',\n 'charact',\n 'good',\n 'comedi',\n 'even',\n 'much',\n 'work',\n 'perform',\n 'feel',\n 'well',\n 'way',\n 'director',\n 'get',\n 'look',\n 'littl',\n 'love',\n 'funni',\n 'come',\n 'enough',\n 'never',\n 'life',\n 'take',\n 'bad',\n 'may']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_30 = np.asarray(np.argsort(np.sum(X_cnt, axis=0))[0,-30:][0, ::-1]).flatten()\n",
    "[reverse_dic[v] for v in top_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_Review, list_Sentiment, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7143,)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3519,)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['violent initi rite audienc much angeliqu open danc guarante karmen enthron among cinema memor women ',\n",
       "       'fill low brow humor gratuit violenc disturb disregard life ',\n",
       "       'transport live fun unapologet dumb ', ...,\n",
       "       'watch chemistri freeman judd howev almost make movi worth see almost ',\n",
       "       'eleg exquisit modul psycholog thriller ',\n",
       "       'charact zigzag suffici develop support film construct around '],\n",
       "      dtype='<U210')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tfizer = TfidfVectorizer(ngram_range= (1,2),max_df=0.3,min_df=7)\n",
    "# X_tfidf =  tfizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=Pipeline([\n",
    "        ('tfidf_vectorizer', TfidfVectorizer(ngram_range= (1,2),max_df=0.3,min_df=7)),\n",
    "        ('rf_classifier', RandomForestClassifier(n_estimators=500,verbose=1,n_jobs=-1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    3.1s\n[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.6s finished\n"
    },
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('tfidf_vectorizer',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=0.3, max_features=None,\n                                 min_df=7, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 toke...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=500, n_jobs=-1,\n                                        oob_score=False, random_state=None,\n                                        verbose=1, warm_start=False))],\n         verbose=False)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1253,  525],\n       [ 498, 1243]], dtype=int64)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}